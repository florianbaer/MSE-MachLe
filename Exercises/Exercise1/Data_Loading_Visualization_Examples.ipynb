{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiZk0zaywk60"
   },
   "source": [
    "## Data Loading, Inspection and Visualization\n",
    "Mainly using pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UO9Q_uZBwk63"
   },
   "outputs": [],
   "source": [
    "# Render our plots inline\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vk4xTsmUwk69"
   },
   "outputs": [],
   "source": [
    "# Import requiered packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SyOUJNyGwk7B"
   },
   "source": [
    "We type some code to simply change the visual style of the plots. (The code below is optional and not necessary, and for now you do not need to understand what exactly is happening.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aPCtvOSNwk7B"
   },
   "outputs": [],
   "source": [
    "# Modifying the style of the graphs\n",
    "matplotlib.style.use(['seaborn-talk', 'seaborn-ticks', 'seaborn-whitegrid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S72XqgQ4wk7O"
   },
   "source": [
    "### Data Loading\n",
    "One can directly load a csv file from an url with pandas or download it locally first and upload it from the local directory on the computer. The `pd.read_csv` method has many options, and you can further read in the [online documentation](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.io.parsers.read_csv.html). \n",
    "In the following, we will focus on the [NYPD Vehicle Collisions](https://data.cityofnewyork.us/Public-Safety/NYPD-Motor-Vehicle-Collisions/h9gi-nx95/data) data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "my8IXs96wk7O"
   },
   "outputs": [],
   "source": [
    "url = 'https://data.cityofnewyork.us/api/views/h9gi-nx95/rows.csv?accessType=DOWNLOAD'\n",
    "df = pd.read_csv(url, low_memory=False)\n",
    "\n",
    "# Let's take a look at the first 5 rows of the dataframe\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZa_rUO9wk7d"
   },
   "source": [
    "### Data Inspection/Visualization\n",
    "Using the `info()` method you can obtain a concise summary of the data, including the data types under which each column has been saved.\n",
    "\n",
    "We can use the method `describe()` to get some statistics of the numeric attributes in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ML7hpRWIwk7d"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `shape` property allows you to see how many rows and columns there are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows/observations - the data numerosity\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features/column/attributes - the data dimensionality\n",
    "df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUAHKFrhwk7i"
   },
   "source": [
    "We can also list the columns and check the data types for each column using `dtypes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u1gvSdQxwk7j"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ja1miMrNwk7n"
   },
   "source": [
    "The `object` type is a string. For some of them, we would like to change the data types using for example the `pd.to_datetime` functions. To this end, we first need to understand how to [parse dates using the Python conventions](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior).\n",
    "\n",
    "The relevant entries from the table are:\n",
    "* `%m` Month as a zero-padded decimal number.\n",
    "* `%d` \tDay of the month as a zero-padded decimal number.\n",
    "* `%Y` Year with century as a decimal number.\n",
    "\n",
    "Now, we can specify how to parse the dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"CRASH DATE\"] = pd.to_datetime(df[\"CRASH DATE\"], format=\"%m/%d/%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"CRASH DATE\", \"BOROUGH\", \"NUMBER OF PERSONS INJURED\"]\n",
    "df.loc[:,cols]\n",
    "# df[[\"CRASH DATE\", \"BOROUGH\", \"NUMBER OF PERSONS INJURED\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting both rows and columns by name (`df.loc`) or by position (`df.iloc`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0:5, [\"CRASH DATE\", \"BOROUGH\", \"NUMBER OF PERSONS INJURED\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[1,4], 0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also change the value of an observation directly in the data frame\n",
    "# df.loc[0, \"BOROUGH\"] = \"BROOKLYN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boolean Indexing\n",
    "To filter rows of a certain kind. Below an example to select data in certain area specified by latitude and longitude ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_condition = (df.LONGITUDE<-50) & (df.LONGITUDE>-74.5) & (df.LATITUDE< 41)\n",
    "df_filtered = df[boolean_condition]\n",
    "# same as:\n",
    "# df_filtered = df[(df.LONGITUDE<-50) & (df.LONGITUDE>-74.5) & (df.LATITUDE< 41)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregation\n",
    "Below you find some aggregation examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum up the number of all injured persons per borough for all different boroughs\n",
    "df.groupby(\"BOROUGH\", as_index=False)[\"NUMBER OF PERSONS INJURED\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply multiple aggregation functions (here \"sum\" and \"max\")\n",
    "df.groupby(\"BOROUGH\", as_index=False)[\"NUMBER OF PERSONS INJURED\"].agg({\"SUM INJURED\": \"sum\", \"MAX INJURED\": \"max\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply an aggregating function on multiple variables by multiple aggregating dimensions\n",
    "df.groupby([\"BOROUGH\",\"VEHICLE TYPE CODE 1\"])[[\"NUMBER OF PERSONS INJURED\",\"CONTRIBUTING FACTOR VEHICLE 1\"]].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGGgbb6twk71"
   },
   "source": [
    "#### Histograms\n",
    "One can examine the distribution of values by using the `hist` command of Pandas, which creates a histogram. (The histogram is also available as `plot.hist()`, or `plot(kind='hist')`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pCjhKEfZwk73"
   },
   "outputs": [],
   "source": [
    "df[\"NUMBER OF PERSONS INJURED\"].hist()\n",
    "# df_filtered[\"NUMBER OF PERSONS INJURED\"].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1VQZyK2wk76"
   },
   "source": [
    "By default, the histogram has ~10 bars. We can change the resolution of the histogram using the `bins` attribute. Larger numbers of `bins` allow for higher resolution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2c-_QIA7wk76"
   },
   "outputs": [],
   "source": [
    "df[\"NUMBER OF PERSONS INJURED\"].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O7NBTKkhwk79"
   },
   "outputs": [],
   "source": [
    "# A quick exposure to various options of the \"hist\" command\n",
    "df[\"NUMBER OF PERSONS INJURED\"].hist(\n",
    "    bins=20, # use 20 bars\n",
    "    range=(0,10), # x-axis from 0 to 10\n",
    "    density=False,  # show normalized count (density=True), or raw counts (density= False)\n",
    "    figsize=(15,5), # controls the size of the plot\n",
    "    alpha=0.8, # make the plot 20% transparent\n",
    "    color='green' # change color\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel Density Estimation (KDE)\n",
    "\n",
    "An alternative to histograms is to use the **kernel density**, which estimates a continuous function, instead of the bucketized counts, which tends to be discontinuous and bumpy. We can access this usind the `.plot(kind='kde')` command. \n",
    "Let's see an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"NUMBER OF PERSONS INJURED\"].plot(\n",
    "    kind='kde', \n",
    "    color='Black', \n",
    "    xlim=(0,5), \n",
    "    figsize=(15,5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNGvJYWMwk8k"
   },
   "source": [
    "#### Analyzing the content of categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hik9O-0Rwk8k"
   },
   "source": [
    "We can also get quick statistics about the common values that appear in each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8sdaD0Aswk8l"
   },
   "outputs": [],
   "source": [
    "df[\"BOROUGH\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMroOATYwk8q"
   },
   "source": [
    "And we can use the \"plot\" command to plot the resulting histogram (more detail at http://pandas.pydata.org/pandas-docs/stable/visualization.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UB5r-v28wk8q"
   },
   "outputs": [],
   "source": [
    "df[\"BOROUGH\"].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pfjMWSclwk9R",
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# horizontal bars (another way to access column in Pandas when there aren't empty spaces in the column name)\n",
    "df_filtered.BOROUGH.value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pivot Tables\n",
    "[Pivot tables](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.pivot_table.html) is one of the most commonly used exploratory tools, and in Pandas they are extremely flexible.\n",
    "\n",
    "Let's use them to break down the accidents by borough and contributing factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = pd.pivot_table(\n",
    "    data = df,\n",
    "    index = 'CONTRIBUTING FACTOR VEHICLE 1',\n",
    "    columns = 'BOROUGH',\n",
    "    aggfunc = 'count',\n",
    "    values = 'COLLISION_ID'\n",
    ")\n",
    "pivot.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples\n",
    "\n",
    "**Example 1:** Find the dates with most accidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"CRASH DATE\"].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UqGlRMz2wk_J"
   },
   "source": [
    "**Example 2:** Find out the 10 most common contributing factors to the collisions. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "coGEV_ZTwk_K"
   },
   "outputs": [],
   "source": [
    "df_filtered['CONTRIBUTING FACTOR VEHICLE 1'].value_counts().head(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hC16MAZ3wk_N"
   },
   "source": [
    "Now let's plot a histogram of the above list. Note that we skip the first element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNWjM8Viwk_N"
   },
   "outputs": [],
   "source": [
    "df_filtered['CONTRIBUTING FACTOR VEHICLE 1'].value_counts()[1:11].plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dCgpcHewk_Q"
   },
   "source": [
    "**Example 3:** Find out how many collisions had 0 person injured, 1 person injured, etc. persons injured in each accident. \n",
    "\n",
    "The `.plot(logy=True)` option is used in the plot to make the y-axis logarigthmic.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uMSpmACuwk_R"
   },
   "outputs": [],
   "source": [
    "plot = (\n",
    "    df['NUMBER OF PERSONS INJURED'] # take the num of injuries column\n",
    "    .value_counts() # compure the freuquency of each value\n",
    "    .sort_index() # sort the results based on the index value instead of the frequency, \n",
    "                  # which is the default for value_counts\n",
    "    .plot( # and plot the results\n",
    "        kind='line', # we use a line plot because the x-axis is numeric/continuous\n",
    "        marker='o',  # we use a marker to mark where we have data points \n",
    "        logy=True # make the y-axis logarithmic\n",
    "    )\n",
    ")\n",
    "plot.set_xlabel(\"Number of injuries\")\n",
    "plot.set_ylabel(\"Number of collisions\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2X-81qUGwk_W"
   },
   "source": [
    "**Example 3:** Plot the number of accidents per day. \n",
    "Ensure that your date column is in the right datatype and that it is properly sorted, before plotting. The [resample](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.resample.html) command is used to change the frequency from one day, to, say, a month. The `drop` command is used to delete rows or columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pQU3ghozwk_W"
   },
   "outputs": [],
   "source": [
    "# Date converted to proper date format\n",
    "df[\"CRASH DATE\"] = pd.to_datetime(df[\"CRASH DATE\"], format=\"%m/%d/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1tb4v7QFwk_Y",
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df[\"CRASH DATE\"].value_counts() # count the number of accidents per day\n",
    "    .sort_index() # sort the dates\n",
    "    .resample('1M') # take periods of 1 month\n",
    "    .sum() # sum the number of accidents per month\n",
    "    .drop(pd.to_datetime('2019-04-30'), axis='index') # drop the current month\n",
    "    .plot() # plot the result\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y22n-5VJwk_Z"
   },
   "source": [
    "**Example 4:** Plot the accidents in map. To do this we use a scatter plot using the `plot(kind='scatter', x=..., y=....)` command, and use the `LATITUDE` and `LONGITUDE` parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-8BgKbdQwk_a"
   },
   "outputs": [],
   "source": [
    "# We do data filtering by specifying a selection condition to limit the lat/long values \n",
    "# to be values idicating the NYC region. Remaining are probably wrong inputs.\n",
    "cleandf = df[(df.LONGITUDE<-50) & (df.LONGITUDE>-74.5) & (df.LATITUDE< 41)]\n",
    "\n",
    "cleandf[ (df.LATITUDE>40) & (df.LATITUDE<41) & (df.LONGITUDE> -74.6) & (df.LONGITUDE<-50) ].plot(\n",
    "    figsize = (20,15),\n",
    "    kind = 'scatter',\n",
    "    x = 'LONGITUDE',\n",
    "    y = 'LATITUDE',\n",
    "    s = 1, # make each dot to be very small \n",
    "    alpha = 0.05 # makes each point 95% transparent\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAOhFrcmwk_n"
   },
   "source": [
    "### 2d histograms, density plots, and contour plots\n",
    "In the picture above, we can visually see that Manhattan, especially eastern midtown, and the area downtown near the entrance to the bridges, has a higher density. We can also derive histograms and density plots on 2-dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ReZjGc3Gwk_n"
   },
   "source": [
    "#### Hexagonal bin plot\n",
    "The hexbin plot created a 2-d histogram, where the color signals the number of points within a particular area. The `gridsize` parameter indicates the number of hexagones in the x direction. Higher values offer higher granularity, but very high values tend to create sparsity, when we do not have enough data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L6VvnKkhwk_n"
   },
   "outputs": [],
   "source": [
    "# Hexbin plot\n",
    "cleandf.plot(\n",
    "    kind='hexbin',\n",
    "    x='LONGITUDE',\n",
    "    y='LATITUDE',\n",
    "    gridsize=100,\n",
    "    cmap=plt.cm.Blues,\n",
    "    figsize=(10, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUFYZc6nwk_q"
   },
   "source": [
    "#### 2d density  and contour plots\n",
    "An alternative to the hexbin plots is to use density plots in two dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nfq8xEMAwk_r"
   },
   "outputs": [],
   "source": [
    "# Basic 2D density plot\n",
    "plt.subplots(figsize=(20, 15))\n",
    "\n",
    "# We take a sample, because density plots take a long time to compute\n",
    "# and a sample is typically as good as the full dataset\n",
    "sample = cleandf.sample(10000)\n",
    "\n",
    "sns.kdeplot(\n",
    "    sample.LONGITUDE,\n",
    "    sample.LATITUDE,\n",
    "    gridsize=100,  # controls the resolution\n",
    "    cmap=plt.cm.rainbow,  # color scheme\n",
    "    shade= True, # whether to have a density plot (True), or just the contours (False)\n",
    "    alpha=0.5,\n",
    "    shade_lowest=False,\n",
    "    n_levels=50  # How many contours/levels to have\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bArlRc1wk_v"
   },
   "outputs": [],
   "source": [
    "# Basic 2D contour plot\n",
    "plt.subplots(figsize=(20, 15))\n",
    "\n",
    "# We take a sample, because density plots take a long time to compute\n",
    "# and a sample is typically as good as the full dataset\n",
    "sample = cleandf.sample(10000)\n",
    "\n",
    "sns.kdeplot(\n",
    "    sample.LONGITUDE,\n",
    "    sample.LATITUDE,\n",
    "    gridsize=100,\n",
    "    cmap=plt.cm.rainbow,\n",
    "    shade=False,\n",
    "    shade_lowest=False,\n",
    "    n_levels=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ww-z3flPwk_y"
   },
   "source": [
    "#### Combining Plots\n",
    "So far, we examined how to create individual plots. We can even combine multiple plots together, using the ax parameter. So, let's say that we want to combine the scatter plots with the contour plot above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H81Nnlbhwk_y"
   },
   "outputs": [],
   "source": [
    "sample = cleandf.sample(10000)\n",
    "\n",
    "scatterplot = cleandf.plot(\n",
    "    kind='scatter',\n",
    "    x='LONGITUDE',\n",
    "    y='LATITUDE',\n",
    "    figsize=(20, 15),\n",
    "    s=0.5,\n",
    "    alpha=0.1)\n",
    "\n",
    "sns.kdeplot(\n",
    "    sample.LONGITUDE,\n",
    "    sample.LATITUDE,\n",
    "    gridsize=100,\n",
    "    cmap=plt.cm.rainbow,\n",
    "    shade=False,\n",
    "    shade_lowest=False,\n",
    "    n_levels=20,\n",
    "    alpha=1,\n",
    "    ax=scatterplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "EDA and Data visualization.ipynb",
   "provenance": []
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
